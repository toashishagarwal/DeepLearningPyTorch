{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DIHncC35xt31"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def onehot_encoder(position,depth):\n",
        "    onehot=torch.zeros((depth,))\n",
        "    onehot[position]=1\n",
        "    return onehot\n",
        "\n",
        "def int_to_onehot(number):\n",
        "  onehot=onehot_encoder(number, 100)\n",
        "  return onehot"
      ],
      "metadata": {
        "id": "RzJqSq-ayzQo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate 10 ints (between 0 & 99) that are multiple of 5\n",
        "def gen_sequence():\n",
        "    indices = torch.randint(0, 20, (10,))\n",
        "    sequence = indices*5\n",
        "    return sequence\n",
        "\n",
        "sequence = gen_sequence()\n",
        "print(sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJZ6azL_x4_H",
        "outputId": "0a439ee2-b86e-4acb-f2dd-c3663e1a59bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([60, 65, 40, 35, 95, 80, 40, 50, 45, 65])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert each int in preceding step into one-hot var\n",
        "def gen_batch():\n",
        "  sequence = gen_sequence()\n",
        "  batch=[int_to_onehot(i).numpy() for i in sequence]\n",
        "  batch=np.array(batch)\n",
        "  return torch.tensor(batch)\n",
        "\n",
        "batch=gen_batch()\n",
        "print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnTMvzg9yhsG",
        "outputId": "248a8dac-334d-4e81-d4a3-d40bcbf34574"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_to_num(data):\n",
        "    num=torch.argmax(data,dim=-1)\n",
        "    return num\n",
        "numbers=data_to_num(batch)\n",
        "print(numbers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Whn4Nheez_Ad",
        "outputId": "35bd0008-52ec-44b6-f717-f426a7dbb00f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([65, 90, 25, 55, 55, 40, 50, 45, 60, 95])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Discriminator\n",
        "D=nn.Sequential(\n",
        "    nn.Linear(100,1),\n",
        "    nn.Sigmoid()).to(device)"
      ],
      "metadata": {
        "id": "tph_p-aD68k4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator\n",
        "\n",
        "G=nn.Sequential(\n",
        "    nn.Linear(100,100),\n",
        "    nn.ReLU()).to(device)\n"
      ],
      "metadata": {
        "id": "cTGBBUlr7k5z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn=nn.BCELoss()\n",
        "lr=0.0005\n",
        "optimD=torch.optim.Adam(D.parameters(),lr=lr)\n",
        "optimG=torch.optim.Adam(G.parameters(),lr=lr)"
      ],
      "metadata": {
        "id": "Xo4bh96g8FJ5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_labels=torch.ones((10,1)).to(device)\n",
        "fake_labels=torch.zeros((10,1)).to(device)"
      ],
      "metadata": {
        "id": "cXFkSpuTyOKf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_D_G(D,G,loss_fn,optimD,optimG):\n",
        "    # Generate examples of real data\n",
        "    true_data=gen_batch().to(device)\n",
        "\n",
        "    # use 1 as labels since they are real\n",
        "    preds=D(true_data)\n",
        "    loss_D1=loss_fn(preds,real_labels.reshape(10,1))\n",
        "    optimD.zero_grad()\n",
        "    loss_D1.backward()\n",
        "    optimD.step()\n",
        "\n",
        "    # train D on fake data\n",
        "    noise=torch.randn(10,100).to(device)\n",
        "    generated_data=G(noise)\n",
        "\n",
        "    # use 0 as labels since they are fake\n",
        "    preds=D(generated_data)\n",
        "    loss_D2=loss_fn(preds,fake_labels.reshape(10,1))\n",
        "    optimD.zero_grad()\n",
        "    loss_D2.backward()\n",
        "    optimD.step()\n",
        "\n",
        "    # train G\n",
        "    noise=torch.randn(10,100).to(device)\n",
        "    generated_data=G(noise)\n",
        "\n",
        "    # use 1 as labels since G wants to fool D\n",
        "    preds=D(generated_data)\n",
        "    loss_G=loss_fn(preds,real_labels.reshape(10,1))\n",
        "    optimG.zero_grad()\n",
        "    loss_G.backward()\n",
        "    optimG.step()\n",
        "    return generated_data"
      ],
      "metadata": {
        "id": "LDxOuFUuyg40"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStop:\n",
        "    def __init__(self, patience=1000):    #A\n",
        "        self.patience = patience\n",
        "        self.steps = 0\n",
        "        self.min_gdif = float('inf')\n",
        "    def stop(self, gdif):    #B\n",
        "        if gdif < self.min_gdif:    #C\n",
        "            self.min_gdif = gdif\n",
        "            self.steps = 0\n",
        "        elif gdif >= self.min_gdif:\n",
        "            self.steps += 1\n",
        "        if self.steps >= self.patience:    #D\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "stopper=EarlyStop(800)    #A\n",
        "\n",
        "mse=nn.MSELoss()\n",
        "real_labels=torch.ones((10,1)).to(device)\n",
        "fake_labels=torch.zeros((10,1)).to(device)\n",
        "def distance(generated_data):    #B\n",
        "    nums=data_to_num(generated_data)\n",
        "    remainders=nums%5\n",
        "    ten_zeros=torch.zeros((10,1)).to(device)\n",
        "    mseloss=mse(remainders,ten_zeros)\n",
        "    return mseloss\n",
        "\n",
        "for i in range(10000):\n",
        "    gloss=0\n",
        "    dloss=0\n",
        "    generated_data=train_D_G(D,G,loss_fn,optimD,optimG)    #C\n",
        "    dis=distance(generated_data)\n",
        "    if stopper.stop(dis)==True:\n",
        "        break\n",
        "    if i % 50 == 0:\n",
        "        print(data_to_num(generated_data))    #D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVXN2-ZlzDeV",
        "outputId": "3f0b4da0-bf11-45c4-b097-1b2c3f8dc185"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2, 42, 20, 66, 58,  9, 13, 21, 38, 39])\n",
            "tensor([34, 20, 63, 33,  1, 21,  9, 44, 77, 66])\n",
            "tensor([67, 21,  8, 20, 36, 90, 75, 93, 52, 93])\n",
            "tensor([53, 17, 70, 17, 69, 46, 21, 69, 54, 44])\n",
            "tensor([29, 44, 70, 12, 42, 70, 17, 33, 19, 50])\n",
            "tensor([ 0,  4, 85, 12, 85, 20, 85, 85, 66, 68])\n",
            "tensor([53, 53, 11, 73, 66, 22, 16, 67, 44, 70])\n",
            "tensor([68, 20, 66, 68, 68,  1, 69, 81, 85,  6])\n",
            "tensor([85, 85, 85, 70, 85, 39, 85, 15, 85, 22])\n",
            "tensor([92, 80, 70, 66, 69, 20, 61, 70, 20,  4])\n",
            "tensor([66, 66, 55,  0, 20, 85, 85, 62, 66, 70])\n",
            "tensor([70,  0, 85, 13, 70, 67,  4, 20, 85, 70])\n",
            "tensor([66, 75, 10, 30, 85, 32, 70, 70, 75, 80])\n",
            "tensor([75, 11, 40, 20, 80, 45,  0, 85, 80, 20])\n",
            "tensor([15, 25, 75, 25, 55, 10, 25, 60, 15, 80])\n",
            "tensor([70, 25, 25, 80, 80, 75, 80, 80, 75, 30])\n",
            "tensor([45, 25, 75, 25, 80, 40, 30, 25, 25, 15])\n",
            "tensor([45, 25, 40, 55, 40, 50, 25, 95, 40, 35])\n",
            "tensor([40, 25, 40, 45, 35, 30, 15, 75, 55, 45])\n",
            "tensor([10, 55,  0, 45, 30, 25, 10, 25, 15, 30])\n",
            "tensor([95, 10, 95, 45, 90, 45, 45, 10, 95, 45])\n",
            "tensor([ 5, 30, 95,  0, 30, 35, 35, 95, 45, 40])\n",
            "tensor([45, 35, 35, 95, 30, 35, 90, 45, 95,  0])\n",
            "tensor([95, 10, 95, 95, 95, 45, 40, 40, 95, 90])\n",
            "tensor([ 0, 95, 60,  5, 35, 40, 95, 95, 80, 95])\n",
            "tensor([ 5, 95, 40, 50, 90, 60,  0, 65, 95, 80])\n",
            "tensor([60, 60, 60,  0, 65, 15, 90, 95,  5, 65])\n",
            "tensor([95,  0, 65, 80, 80, 60, 60, 65, 50, 50])\n"
          ]
        }
      ]
    }
  ]
}